@article{zhang2024improving,
  title={Improving diffusion inverse problem solving with decoupled noise annealing},
  author={Zhang, Bingliang and Chu, Wenda and Berner, Julius and Meng, Chenlin and Anandkumar, Anima and Song, Yang},
  journal={arXiv preprint arXiv:2407.01521},
  year={2024},
  bibtex_show={true},
   tag1={CVPR},
  abstract={Diffusion models have recently achieved success in solving Bayesian inverse problems with learned data priors. Current methods build on top of the diffusion sampling process, where each denoising step makes small modifications to samples from the previous step. However, this process struggles to correct errors from earlier sampling steps, leading to worse performance in complicated nonlinear inverse problems, such as phase retrieval. To address this challenge, we propose a new method called Decoupled Annealing Posterior Sampling (DAPS) that relies on a novel noise annealing process. Specifically, we decouple consecutive steps in a diffusion sampling trajectory, allowing them to vary considerably from one another while ensuring their time-marginals anneal to the true posterior as we reduce noise levels. This approach enables the exploration of a larger solution space, improving the success rate for accurate reconstructions. We demonstrate that DAPS significantly improves sample quality and stability across multiple image restoration tasks, particularly in complicated nonlinear inverse problems.},
  code={https://github.com/zhangbingliang2019/DAPS},
  pdf={https://arxiv.org/pdf/2407.01521},
  website={https://daps-inverse-problem.github.io/},
  preview={daps.png}
}


@inproceedings{zhenginversebench,
  title={InverseBench: Benchmarking Plug-and-Play Diffusion Models for Scientific Inverse Problems},
  author={Zheng, Hongkai and Chu, Wenda and Zhang, Bingliang and Wu, Zihui and Wang, Austin and Feng, Berthy and Zou, Caifeng and Sun, Yu and Kovachki, Nikola Borislavov and Ross, Zachary E and others},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  bibtex_show={true},
   tag1={ICLR (Spotlight)},
  abstract={Plug-and-play diffusion models have emerged as a promising research direction for solving inverse problems. However, current studies primarily focus on natural image restoration, leaving the performance of these algorithms in scientific inverse problems largely unexplored. To address this gap, we introduce InverseBench, a framework that evaluates diffusion models across five distinct scientific inverse problems. These problems present unique structural challenges that differ from existing benchmarks, arising from critical scientific applications such as optical tomography, medical imaging, black hole imaging, seismology, and fluid dynamics. With InverseBench, we benchmark 14 inverse problem algorithms that use plug-and-play diffusion models against strong, domain-specific baselines, offering valuable new insights into the strengths and weaknesses of existing algorithms.},
  code={https://github.com/devzhk/InverseBench},
  pdf={https://openreview.net/pdf?id=U3PBITXNG6},
  website={https://devzhk.github.io/InverseBench/},
  preview={inv-bench.png}
}

@article{wu2024principled,
  title={Principled probabilistic imaging using diffusion models as plug-and-play priors},
  author={Wu, Zihui and Sun, Yu and Chen, Yifan and Zhang, Bingliang and Yue, Yisong and Bouman, Katherine},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={118389--118427},
  year={2024},
  bibtex_show={true},
   tag1={NeurIPS},
  abstract={Diffusion models (DMs) have recently shown outstanding capabilities in modeling complex image distributions, making them expressive image priors for solving Bayesian inverse problems. However, most existing DM-based methods rely on approximations in the generative process to be generic to different inverse problems, leading to inaccurate sample distributions that deviate from the target posterior defined within the Bayesian framework. To harness the generative power of DMs while avoiding such approximations, we propose a Markov chain Monte Carlo algorithm that performs posterior sampling for general inverse problems by reducing it to sampling the posterior of a Gaussian denoising problem. Crucially, we leverage a general DM formulation as a unified interface that allows for rigorously solving the denoising problem with a range of state-of-the-art DMs. We demonstrate the effectiveness of the proposed method on six inverse problems (three linear and three nonlinear), including a real-world black hole imaging problem. Experimental results indicate that our proposed method offers more accurate reconstructions and posterior estimation compared to existing DM-based imaging inverse methods.},
  code={https://github.com/zihuiwu/PnP-DM-public},
  pdf={https://arxiv.org/pdf/2405.18782},
  website={https://imaging.cms.caltech.edu/pnpdm/},
  preview={pnpdm.png}
}

@inproceedings{kumari2023multi,
  title={Multi-concept customization of text-to-image diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1931--1941},
  year={2023},
  bibtex_show={true},
  tag1={CVPR},
  abstract={While generative models produce high-quality images of concepts learned from a large-scale database, a user often wishes to synthesize instantiations of their own concepts (for example, their family, pets, or items). Can we teach a model to quickly acquire a new concept, given a few examples? Furthermore, can we compose multiple new concepts together? We propose Custom Diffusion, an efficient method for augmenting existing text-to-image models. We find that only optimizing a few parameters in the text-to-image conditioning mechanism is sufficiently powerful to represent new concepts while enabling fast tuning (~6 minutes). Additionally, we can jointly train for multiple concepts or combine multiple fine-tuned models into one via closed-form constrained optimization. Our fine-tuned model generates variations of multiple new concepts and seamlessly composes them with existing concepts in novel settings. Our method outperforms or performs on par with several baselines and concurrent works in both qualitative and quantitative evaluations while being memory and computationally efficient.},
  code={https://github.com/adobe-research/custom-diffusion},
  pdf={https://arxiv.org/pdf/2212.04488},
  website={https://www.cs.cmu.edu/\~{}custom-diffusion/},
  preview={custom-diffusion.png}
}

@inproceedings{kumari2023ablating,
  title={Ablating concepts in text-to-image diffusion models},
  author={Kumari, Nupur and Zhang, Bingliang and Wang, Sheng-Yu and Shechtman, Eli and Zhang, Richard and Zhu, Jun-Yan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22691--22702},
  year={2023},
   bibtex_show={true},
   tag1={ICCV},
  abstract={Large-scale text-to-image diffusion models can generate high-fidelity images with powerful compositional ability. However, these models are typically trained on an enormous amount of Internet data, often containing copyrighted material, licensed images, and personal photos. Furthermore, they have been found to replicate the style of various living artists or memorize exact training samples. How can we remove such copyrighted concepts or images without retraining the model from scratch? To achieve this goal, we propose an efficient method of ablating concepts in the pretrained model, i.e., preventing the generation of a target concept. Our algorithm learns to match the image distribution for a target style, instance, or text prompt we wish to ablate to the distribution corresponding to an anchor concept. This prevents the model from generating target concepts given its text condition. Extensive experiments show that our method can successfully prevent the generation of the ablated concept while preserving closely related concepts in the model.},
  code={https://github.com/nupurkmr9/concept-ablation},
  pdf={https://arxiv.org/pdf/2303.13516},
  website={https://www.cs.cmu.edu/\~{}concept-ablation/},
  preview={concept-ablation.png}
}

@inproceedings{zhou2021continuously,
  title={Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization},
  author={Zhou, Zihan and Fu, Wei and Zhang, Bingliang and Wu, Yi},
  booktitle={International Conference on Learning Representations},
  year={2021},
  bibtex_show={true},
   tag1={ICLR},
  abstract={We present Reward-Switching Policy Optimization (RSPO), a paradigm to discover diverse strategies in complex RL environments by iteratively finding novel policies that are both locally optimal and sufficiently different from existing ones. To encourage the learning policy to consistently converge towards a previously undiscovered local optimum, RSPO switches between extrinsic and intrinsic rewards via a trajectory-based novelty measurement during the optimization process. When a sampled trajectory is sufficiently distinct, RSPO performs standard policy optimization with extrinsic rewards. For trajectories with high likelihood under existing policies, RSPO utilizes an intrinsic diversity reward to promote exploration. Experiments show that RSPO is able to discover a wide spectrum of strategies in a variety of domains, ranging from single-agent particle-world tasks and MuJoCo continuous control to multi-agent stag-hunt games and StarCraftII challenges.},
  pdf={https://arxiv.org/pdf/2204.02246},
  preview={diversity-rl.png}
}